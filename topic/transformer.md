### ChenKalantidisLiYF_2018 - [$A^2$-Nets: Double Attention Networks](https://arxiv.org/pdf/1810.11579.pdf)

- basic idea: learn the global features and local feature, then weight local features according to the similarity to global features, so that local features share information with global features.
- conv backbone + transformer


### ShenZhangZhaoYL_2018 - [Efficient Attention- Attention with Linear Complexities](https://arxiv.org/pdf/1812.01243.pdf)

- basic idea: show when change the order of matrix muliplication, the results is equivalent but the complexity reduce. Provide a new explanation of attention, which is exactly the same to A^2-Net 

### YueSunYuanZDX_2018 - [Compact Generalized Non-local Network](https://arxiv.org/pdf/1810.13125.pdf)

- basic idea: They vectorlized the feature, then use kernel to mapping the feature in the high demension space, then aggregate the info. They claim when they learn the mapping vector to aggeragate each order, they considering the infor from different channels. 

### ChoromanskiLikhosherstovDohanSGSHDBCW_2020 - [Rethinking Attention with Performers](https://arxiv.org/pdf/2009.14794.pdf)

El-NoubyTouvronCaronBDJLNSVJ_2021 - XCiT- Cross-Covariance Image Transformers

KatharopoulosVyasPappasF_2020 - Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention

REVIEW - Anonymous_2022 - Patches Are All You Need?

REVIEW - ZhaiTalbottSrivastavaHGS_2021 - An Attention Free Transformer

TolstikhinHoulsbyKolesnikovBZUYSKULD_2021 - MLP-Mixer- An all-MLP Architecture for Vision

WangLiKhabsaFM_2020 - Linformer- Self-Attention with Linear Complexity

ZhaiTalbottSrivastavaHGZS_2021 - An Attention Free Transformer

(linear attention)

HeoYunHanCCO_tech2021 - Rethinking Spatial Dimensions of Vision Transformers

WuXiaoCodellaLDYZ_tech2021 - CvT- Introducing Convolutions to Vision Transformers

(spatial pooling)

ResNet strikes back: An improved training procedure in timm 
