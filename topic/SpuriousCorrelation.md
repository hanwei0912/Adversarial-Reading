Making deep neural networks right for the right scientific reasons by interacting with their explanations

Noise or signal: The role of image backgrounds in object recognition

Clever hans effect found in a widely used brain tumour mri dataset

 Spectral signatures in backdoor attacks

Analyzing classifiers: Fisher vectors and deep neural networks

Unmasking clever hans predictors and assessing what machines really learn

On feature learning in the presence of spurious correlations.

Finding and removing clever hans: Using explanation methods to debug and improve deep models

Shortcut learning in deep neural networks

Badnets: Identifying vulnerabilities in the machine learning model supply chain

ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness
