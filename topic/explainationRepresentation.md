# Suggested 

## CAM papers

#### [Grad-cam: Visual explanations from deep networks via gradient-based localization](https://arxiv.org/abs/1610.02391)

#### [Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks](https://arxiv.org/pdf/1710.11063.pdf)



## General papers

#### [The mythos of model interpretability](https://arxiv.org/pdf/1606.03490.pdf)

#### [LIME: "Why Should I Trust You?": Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)


-SHAP: A Unified Approach to Interpreting Model Predictions
-Interpretable Explanations of Black Boxes by Meaningful Perturbation
-How Can I Explain This to You? An Empirical Study of Deep Neural
Network Explanation Methods

## Part based
-This Looks Like That: Deep Learning for Interpretable Image
Recognition

## Recent

-Toward interpretable machine learning: Transparent deep neural
networks and beyond
-A Disentangling Invertible Interpretation Network for Explaining
Latent Representations (3 papers from the same guys)

# Randomly Reading




#### Not Just A Black Box: Learning Important Features Through Propagating Activation Differences
#### [Attack to Explain Deep Representation](https://openaccess.thecvf.com/content_CVPR_2020/html/Jalwana_Attack_to_Explain_Deep_Representation_CVPR_2020_paper.html)
#### Robust Semantic Interpretability: Revisiting Concept Activation Vectors
#### Adaptive Clustering of Robust Semantic Representations for Adversarial Image Purification
#### Learning Robust Visual-semantic Mapping for Zero-shot Learning
#### Few-Cost Salient Object Detection with Adversarial-Paced Learning
#### Adaptive Clustering of Robust Semantic Representations for Adversarial Image Purification
#### FIMAP: Feature Importance by Minimal Adversarial Perturbation
#### Adversarial Training and Provable Robustness: A Tale of Two Objectives

Adversarial Robustness through Disentangled Representations


Adversarial Permutation Guided Node Representations for Link Prediction

Achieving Robustness in the Wild via Adversarial Mixing With Disentangled Representations


Learn2Perturb: An End-to-End Feature Perturbation Learning to Improve Adversarial Robustness

Adversarial Examples Improve Image Recognition

Enhancing Intrinsic Adversarial Robustness via Feature Pyramid Decoder

A Unified Approach to Interpreting and Boosting Adversarial Transferability

Improving Adversarial Robustness via Channel-wise Activation Suppressing

