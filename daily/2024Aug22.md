### [ECOR: Explainable CLIP for Object Recognition](https://arxiv.org/pdf/2404.12839)

- Joint probability distribution of category and rationales
- prompt with rationales
- rationales is given by asking GPT3 with prompt "what are useful visual features for distinguishing a {categorty name} in a photo"; search for images via google image AIP using query {category name} which has {attribute name}
- they calculate P(r|I) and P(c|r,I)
- In the experiments, they show the metrics of right category and right rationale(RR), RW,WR,WW

### [gScoreCAM: What objects is CLIP looking at?](https://openaccess.thecvf.com/content/ACCV2022/papers/Chen_gScoreCAM_What_objects_is_CLIP_looking_at_ACCV_2022_paper.pdf)
[code](https://github.com/anguyen8/gScoreCAM)

### [CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor](https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_CLIP_as_RNN_Segment_Countless_Visual_Concepts_without_Training_Endeavor_CVPR_2024_paper.pdf)


### [CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks](https://arxiv.org/pdf/2304.05653)

### [Overcoming Generic Knowledge Loss with Selective Parameter Update](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Overcoming_Generic_Knowledge_Loss_with_Selective_Parameter_Update_CVPR_2024_paper.pdf)
