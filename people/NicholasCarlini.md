## [Nicholas Carlini](https://nicholas.carlini.com/)

### Attack

#### [Cryptanalytic Extraction of Neural Network Models](https://arxiv.org/abs/2003.04884)

#### [Label-Only Membership Inference Attacks](https://arxiv.org/pdf/2007.14321.pdf)
This work is about privacy leakage for machine learning: given a data point and model, determine whether the point was used to train the model.

### Defense

### Robustness
