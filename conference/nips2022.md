## Interpretability

### [Robust Feature-Level Adversaries are Interpretability Tools](https://openreview.net/pdf?id=lQ--doSB2o)

### [Scalable Interpretability via Polynomials](https://openreview.net/pdf?id=TwuColwZAVj)

### [On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach](https://openreview.net/pdf?id=WPXRVQaP9Oq)

### []


## Adversarial attack

### [Isometric 3D Adversarial Examples in the Physical World](https://openreview.net/pdf?id=HOG-G4arLnU)

![fg](figures/e-iso.png)

### [Improving 3D-aware Image Synthesis with A Geometry-aware Discriminator](https://openreview.net/pdf?id=QRp6viwPRaX)

### [GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images](https://openreview.net/pdf?id=GAUwreODU5L)

### [Towards Consistency in Adversarial Classification](https://openreview.net/pdf?id=2_AZxVpFlGP)

### [Adversarial Unlearning: Reducing Confidence Along Adversarial Directions](https://openreview.net/pdf?id=cJ006qBE8Uv)

### [Efficient and Effective Augmentation Strategy for Adversarial Training](https://openreview.net/pdf?id=ODkBI1d3phW)

### [Random Normalization Aggregation for Adversarial Defense](https://openreview.net/pdf?id=K4W92FUXSF9)
