### [Impact of Low-bitwidth Quantization on the Adversarial Robustness for Embedded Neural Networks](https://arxiv.org/pdf/1909.12741.pdf)

1. abstract

In this article, we investigate the adversarial robustness of quantized neural networks under different
threat models for a classical supervised image classification task. We show that quantization does
not offer any robust protection, results in severe form of gradient masking and advance some
hypotheses to explain it. However, we experimentally observe poor transferability capacities which
we explain by quantization value shift phenomenon and gradient misalignment and explore how
these results can be exploited with an ensemble-based defense.


### [FDA: Feature Disruptive Attack](https://arxiv.org/abs/1909.04385)


### [Defending Against Adversarial Examples with K-Nearest Neighbor](https://arxiv.org/abs/1906.09525)

### [Stochastic Activation Pruning for Robust Adversarial Defense](https://ibug.doc.ic.ac.uk/media/uploads/documents/stochastic_activation_pruning.pdf)

