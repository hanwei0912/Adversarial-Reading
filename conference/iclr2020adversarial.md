### ICLR 2020

### Adversarial Defense

[Adversarial lipschitz regularization](https://openreview.net/forum?id=Bke_DertPB)

Adversarially Robust Transfer Learning

Improved Sample Complexities for Deep Networks and Robust Classification via an All-Layer Margin

Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing

Adversarial Example Detection and Classification with Asymmetrical Adversarial Training

#### [Improving Adversarial Robustness Requires Revisiting Misclassified Examples](https://openreview.net/pdf?id=rklOg6EFwS)
##### The work
- investigate the distinctive influence of misclassified and correctly classified examples on the final robustness of adversarial training.

##### How could it related to my work
- It metions about the 

Adversarially Robust Representations with Smooth Encoders

Provable robustness against all adversarial $l_p$-perturbations for $p\geq 1$

Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions

Fast is better than free: Revisiting adversarial training

Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness

Adversarial Training and Provable Defenses: Bridging the Gap

Enhancing Adversarial Defense by k-Winners-Take-All

Intriguing Properties of Adversarial Training at Scale

Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks

Certified Defenses for Adversarial Patches

Jacobian Adversarially Regularized Networks for Robustness

Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks

MMA Training: Direct Input Space Margin Maximization through Adversarial Training

Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness

MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius

Towards Stable and Efficient Training of Verifiably Robust Neural Networks

EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks

Distributionally Robust Neural Networks

### Adversarial Attack
#### [Unrestricted Adversarial Examples via Semantic Manipulation](https://openreview.net/pdf?id=Sye_OgHFwH)

- we instead introduce “unrestricted” perturbations that
manipulate semantically meaningful image-based visual descriptors – color and
texture – in order to generate effective and photorealistic adversarial examples.

- contributions: 1) We propose two novel approaches to generate “unrestricted"
adversarial examples via semantic transformation; 2) We conduct extensive experiments to attack both
image classification and image captioning models on large scale datasets (ImageNet and MSCOCO);
3) We show that our attacks are equipped with unique properties such as smooth cAdv perturbations
and structured tAdv perturbations. 4) We perform comprehensive user studies to show that when
compared to other attacks, our generated adversarial examples appear more natural to humans despite
their large perturbations; 5) We test different adversarial examples against several state of the art
defenses and show that the proposed attacks are more transferable and harder to defend.

Black-Box Adversarial Attack with Transferable Model-based Embedding

Sign Bits Are All You Need for Black-Box Attacks

Breaking Certified Defenses: Semantic Adversarial Examples with Spoofed Robustness Certificates

Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking

BayesOpt Adversarial Attack

Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks

### Common Robust
Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks

AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty

### Rejected
Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness

Extreme Values are Accurate and Robust in Deep Networks

Defective Convolutional Layers Learn Robust CNNs

Sensible adversarial learning

Disentangling Improves VAEs' Robustness to Adversarial Attacks

Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness

Adversarial Robustness Against the Union of Multiple Perturbation Models
