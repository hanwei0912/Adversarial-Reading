## Robustness

### [Amplitude-Phase Recombination: Rethinking Robustness of Convolutional Neural Networks in Frequency Domain](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_Amplitude-Phase_Recombination_Rethinking_Robustness_of_Convolutional_Neural_Networks_in_Frequency_ICCV_2021_paper.html)
In this paper, we notice that the CNN tends to converge at the local optimum which is closely related to the high-frequency components of the training images, while the amplitude spectrum is easily disturbed such as noises or common corruptions. In contrast, more empirical studies found that humans rely on more phase components to achieve robust recognition. This observation leads to more explanations of the CNN's generalization behaviors in both robustness to common perturbations and out-of-distribution detection, and motivates a new perspective on data augmentation designed by re-combing the phase spectrum of the current image and the amplitude spectrum of the distracter image. That is, the generated samples force the CNN to pay more attention to the structured information from phase components and keep robust to the variation of the amplitude.

- A way to augment data

### [Group-Wise Inhibition Based Feature Regularization for Robust Classification](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Group-Wise_Inhibition_Based_Feature_Regularization_for_Robust_Classification_ICCV_2021_paper.html)

- extract the feature and group features channel-wise, and calculate the importance of each feature
- dynamically suppress significant activation values of CNN by group-wise inhibition, but not fixedly or randomly handle them when training
- need training
- use the idea of masked feature for prediction

### [Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2021/papers/Besnier_Triggering_Failures_Out-of-Distribution_Detection_by_Learning_From_Local_Adversarial_Attacks_ICCV_2021_paper.pdf)

- main contribution is a new OOD detection architecture called ObsNet associated with a dedicated training scheme based on Local Adversarial Attacks (LAA)
- two-stage approach with modern deep learning tools in a semantic segmentation context: OOD detection is seperate from segmentation so that not affect the performance (emmmmm...good explaination for simple idea)
- Local Adversarial Attacks: FGSM with binary mask of random shape (mask of random shape is to avoid the noise is similar to the shape of objects, i.e. from the distribution of the training data, it is special for segmentation. Figure 3 is interesting, constraint the region of the noise leads to a smaller norm but personally, I think class wise is better. Since square attack is more powerful, maybe such shape constraint makes improves the success rate....)
- not clear why element-addition between two networks instead of element-multiplation, etc?

## Adversarial Attacks

### [Interpreting Attributions and Interactions of Adversarial Attacks](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Interpreting_Attributions_and_Interactions_of_Adversarial_Attacks_ICCV_2021_paper.html)

1. estimate attributions of different image regions to the decrease of the attacking cost based on the
Shapley value
2. define and quantify interactions among
adversarial perturbation pixels, and decompose the entire perturbation map into *relatively independent perturbation components*

### [Adversarial Attacks Are Reversible With Natural Supervision](https://openaccess.thecvf.com/content/ICCV2021/html/Mao_Adversarial_Attacks_Are_Reversible_With_Natural_Supervision_ICCV_2021_paper.html)

- defense in training time is not enough
- attack damges the incidential structure
- constractive learning
- inference-time defense by restoring the intrinsic structure of the input
- Reverse Attack: using attack to defense 

### [Feature Importance-aware Transferable Adversarial Attacks](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Feature_Importance-Aware_Transferable_Adversarial_Attacks_ICCV_2021_paper.pdf)

- use the idea of the saliency map to weight the feature, and sum up the feature to construct the loss function
- minimize the feature that important to the prediction 

### [TkML-AP: Adversarial Attacks to Top-k Multi-Label Learning](https://openaccess.thecvf.com/content/ICCV2021/html/Hu_TkML-AP_Adversarial_Attacks_to_Top-k_Multi-Label_Learning_ICCV_2021_paper.html)

- TkML task: multi-label classifier
- TkML consistency
- untargeted: predict class outside the top-k 
- solve optimization by iterative gradient descent approach

### [*Augmented Lagrangian Adversarial Attacks*](https://openaccess.thecvf.com/content/ICCV2021/html/Rony_Augmented_Lagrangian_Adversarial_Attacks_ICCV_2021_paper.html)

- white-box attack algorithm to generate minimally perturbed adversarial examples based on augmented lagrangian principles
- generic augmented lagrangian method
- augmented lagrangian attack
- penalty parameter adaptation

### [Meta Gradient Adversarial Attack](https://openaccess.thecvf.com/content/ICCV2021/html/Yuan_Meta_Gradient_Adversarial_Attack_ICCV_2021_paper.html)

- improve transferability
- iteratively simulate white-box and black-box attack
- narrow the gap between the gradient directions in meta-train(white-box) and meta-test(black-box) step
- model zoo: sampling to choose the task

### [Meta-Attack: Class-Agnostic and Model-Agnostic Physical Adversarial Attack](https://openaccess.thecvf.com/content/ICCV2021/html/Feng_Meta-Attack_Class-Agnostic_and_Model-Agnostic_Physical_Adversarial_Attack_ICCV_2021_paper.html)

- class-agnostic, model-agnostic, physical adversarial attack
- similate color and shape distortions
- genalize to novel images and novel DNN models by accessing a few digital and physical images (few-shot learning)
- generative attack model: 1) successful digital attack; 2) robustness to 1:1-D2P transformation; 3) robustness to spacial transformations; 4) Lp constraint


## Adversarial Defense

### [Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2021/html/Xu_Dynamic_Divide-and-Conquer_Adversarial_Training_for_Robust_Semantic_Segmentation_ICCV_2021_paper.html)

- sematic segmentation task
- divide pixels in safe trainning region and perturbation sensitive region which close to boundary
- main branch; mask branch and auxiliary branch
- mask branch give the mask to combine the safe rigion feature in main branch and sensitive region feature in auxiliary branch

### [Calibrated Adversarial Refinement for Stochastic Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2021/html/Kassapis_Calibrated_Adversarial_Refinement_for_Stochastic_Semantic_Segmentation_ICCV_2021_paper.html)

- propose a novel two-stage, cascaded approach for calibrated adversarial refinement: (i) a standard segmentation network is trained with categorical cross-entropy to predict a pixelwise probability distribution over semantic classes and (ii) an adversarially trained stochastic network is used to model the inter-pixel correlations to refine the output of the first network into coherent samples. 
- Importantly, to calibrate the refinement network and prevent mode collapse, the expectation of the samples in the second stage is matched to the probabilities predicted in the first.

### [Adversarial Example Detection Using Latent Neighborhood Graph](https://openaccess.thecvf.com/content/ICCV2021/html/Abusnaina_Adversarial_Example_Detection_Using_Latent_Neighborhood_Graph_ICCV_2021_paper.html)

- adversarial and its original images are identical in image space but very different in the lantent space.
- latent neighborhood graph: node retrieval and edge estimation
- node retrieval: knn in euclidean distance over the embedding space
- edge estimation: model the relation between two nodes as a sigmoid function of the euclidean distance between them.
- graph discriminator: input: embedding matrix and the adjacency matrix; graph attention network: 4 consecutive graph attention layers+dense layer+dense classification layer+two-class output. 

### [Attack as the Best Defense: Nullifying Image-to-image Translation GANs via Limit-aware Adversarial Attack](https://openaccess.thecvf.com/content/ICCV2021/papers/Yeh_Attack_As_the_Best_Defense_Nullifying_Image-to-Image_Translation_GANs_via_ICCV_2021_paper.pdf)

- the goal of the work is to transform modified images to original version. They use limit-aware RGF and the gradient sliding mechanism to estimate the gradient that adheres to the adversarial limit.
- Nullifying Attack (black-box setting adversarial attack on Img2Img GAM): attack with Nullifying loss, transform adversarial examples back to original one. (need training data about the original and adversarial pairs)
- Limit-aware RGF:
- gradient sliding mechanism
- self-guiding prior:

## Interpretability

##### [Generic Attention-Model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers](https://openaccess.thecvf.com/content/ICCV2021/html/Chefer_Generic_Attention-Model_Explainability_for_Interpreting_Bi-Modal_and_Encoder-Decoder_Transformers_ICCV_2021_paper.html)

- transformer-based model
- transformer interpretability
- task combine text and images
- aggregating attention heads (integrated gradients + attention maps)
- co-attention between images and texts

##### [Self-Supervised Geometric Features Discovery via Interpretable Attention for Vehicle Re-Identification and Beyond](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Self-Supervised_Geometric_Features_Discovery_via_Interpretable_Attention_for_Vehicle_Re-Identification_ICCV_2021_paper.pdf)

- for the task Vehicle-re-identification
- get geometric local features  global representation
- use self-supervised representation

### [Interpretable Image Recognition by Constructing Transparent Embedding Space](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Interpretable_Image_Recognition_by_Constructing_Transparent_Embedding_Space_ICCV_2021_paper.html)

- transparent embedding space
- grassmann manifold
- objective: construct the basis concpets and build the dicesion function
- embedding space learning -> construct the basic conceots: (1)orthonormilay loss, basis vectors should be indipendent to each other; (2) separation for class-aware subspace, maximize the projection metric amoing each pair of subspaces; (3) hight-level patches grouping, compact patches from same concept and separat patches from different concpet; (4) identification: classification cross entropy
- embedding space transparent -> know the meaning of each basic concept
- concept based classification

### [Stochastic Partial Swap: Enhanced Model Generalization and Interpretability for Fine-Grained Recognition](https://openaccess.thecvf.com/content/ICCV2021/html/Huang_Stochastic_Partial_Swap_Enhanced_Model_Generalization_and_Interpretability_for_Fine-Grained_ICCV_2021_paper.html)

- learn semantic representation (mid-level) with less cost
- injecting noise into features during training to suppress over response of some filters and encourage filters to jointly represent a concept
- randomly select sample from the same mini-batch as noise source and swap their partical feature elements element-wise
- compare to dropout, it claims "it equips a regularization effect similar to dropout"
- compute each region's contribution score to the prediction; generate the attention map corresponding each location i

### [*Statistically Consistent Saliency Estimation*](https://openaccess.thecvf.com/content/ICCV2021/papers/Luo_Statistically_Consistent_Saliency_Estimation_ICCV_2021_paper.pdf)

- statistically valid technique for model-agnostic saliency estimation: perturb images and find the most important pixel for the classifier
- linearly estimated gradient: f(x): the difference of two class probabilities; LEG: arg min_g E_{x~F+x_o}[(f(x)-f(x_o)-vec(g)^Tvec(x_o-x))^2]
- local approximation, using TV as constraint
- linear problem

### [Finding Representative Interpretations onConvolutional Neural Networks](https://openaccess.thecvf.com/content/ICCV2021/papers/Lam_Finding_Representative_Interpretations_on_Convolutional_Neural_Networks_ICCV_2021_paper.pdf)

- unsupervised approach to produce a highly representative interpretation
- The goal is to find and visualize the common decision logic of a CNN that governs the predictions on an input image
- approximiate the convex polytope inside decision boundary of netowrk
- 1) candidate pool generation; 2) submodular optimization; 3) semantic distance ranking 

### [Attentional Pyramid Pooling of Salient Visual Residuals for Place Recognition](https://openaccess.thecvf.com/content/ICCV2021/html/Peng_Attentional_Pyramid_Pooling_of_Salient_Visual_Residuals_for_Place_Recognition_ICCV_2021_paper.html)

- retreival task
- incorporates three types of attention modules to model the saliency of local feature in individual, spatial and cluster dimensions respectively
- (1) To inhibit task-irrelevant local features, a semantic-reinforced local weighting scheme is employed for local feature refinement;
- (2) To leverage the spatial context, an attentional pyramid structure is constructed to adaptively encode regional features according to their relative spatial saliency;
- (3) To distinguish the different importance of visual clusters to the task, a parametric normalization is proposed to adjust their contribution to image descriptor generation.

### [Salient Object Ranking with Position-Preserved Attention](https://openaccess.thecvf.com/content/ICCV2021/papers/Fang_Salient_Object_Ranking_With_Position-Preserved_Attention_ICCV_2021_paper.pdf)

- detection branch: give boxes, classes, masks
- salient object ranking Branch（multi-task learning fashion）: using Position-Preserved Attention (PPA) to get contextualized representations and maskes the final ranking prediction via FC layers
- PPA: position embedding stage + feature interaction stage
- position affect the object detection
