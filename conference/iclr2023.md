## Adversarial

On Achieving Optimal Adversarial Test Error

TextShield: Beyond Successfully Detecting Adversarial Sentences in NLP

Neural Architecture Design and Robustness: A Dataset

Squeeze Training for Adversarial Robustness

Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples

Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness

Towards Robustness Certification Against Universal Perturbations

Adversarial Imitation Learning with Preferences

Boosting Adversarial Transferability Using Dynamic Cues

Extracting Robust Models with Uncertain Examples

DAVA: Disentangling Adversarial Variational Autoencoder

Data Augmentation Alone Can Improve Adversarial Training

AGRO: Adversarial Discovery of Error-prone Groups for Robust Optimization

Part-Based Models Improve Adversarial Robustness

On The Perils of Cascading Robust Classifiers

Adversarial Training Descends Without Descent: Finding Actual Descent Directions Based on Danskinâ€™s Theorem

Holistic Adversarially Robust Pruning

Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition

Toward Adversarial Training on Contextualized Language Representation

Defending Against Adversarial Audio Via Diffusion Model

Certified Defences Against Adversarial Patch Attacks on Semantic Segmentation

Near-Optimal Adversarial Reinforcement Learning with Switching Costs

Revisiting Graph Adversarial Attack and Defense From A Data Distribution Perspective

Rethinking The Effect of Data Augmentation in Adversarial Contrastive Learning

Adversarial Training of Self-supervised Monocular Depth Estimation Against Physical-World Attacks

Inequality Phenomenon in $l_{\infty}$-adversarial Training, and Its Unrealized Threats

Generative Modeling Helps Weak Supervision (and Vice Versa)

Is Adversarial Training Really A Silver Bullet for Mitigating Data Poisoning?

Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness

Certifiably Robust Policy Learning Against Adversarial Multi-Agent Communication

Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation

Free Lunch for Domain Adversarial Training: Environment Label Smoothing

On The Robustness of Safe Reinforcement Learning Under Observational Perturbations

Why Adversarial Training Can Hurt Robust Accuracy

Domain Generalisation Via Domain Adaptation: An Adversarial Fourier Amplitude Approach

Understanding Zero-shot Adversarial Robustness for Large-Scale Models

Combating Exacerbated Heterogeneity for Robust Decentralized Models

Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders

Adversarial Attacks on Adversarial Bandits

Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms

Chasing All-Round Graph Representation Robustness: Model, Training, and Optimization

TextGrad: Advancing Robustness Evaluation in NLP By Gradient-Driven Optimization

DensePure: Understanding Diffusion Models Towards Adversarial Robustness

Revisiting Robustness in Graph Machine Learning

(Certified!!) Adversarial Robustness for Free!

Canary in A Coalmine: Better Membership Inference with Ensembled Adversarial Queries

Revisiting Adapters with Adversarial Training


## Interpretability

Interpretability in The Wild: A Circuit for Indirect Object Identification in GPT-2 Small

Interpretable Debiasing of Vectorized Language Representations with Iterative Orthogonalization

Interpretable Single/Multi-label Text Classification with Unsupervised Constituent-label Alignments

MultiViz: Towards Visualizing and Understanding Multimodal Models

Progress Measures for Grokking Via Mechanistic Interpretability

Interpretability with Full Complexity By Constraining Feature Information

STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK

CoRTX: Contrastive Framework for Real-time Explanation

Explaining RL Decisions with Trajectories

An Additive Instance-Wise Approach to Multi-class Model Interpretation

ODAM: Gradient-based Instance-Specific Visual Explanations for Object Detection

WikiWhy: Answering and Explaining Cause-and-Effect Questions

Contrastive Corpus Attribution for Explaining Representations

Temporal Dependencies in Feature Importance for Time Series Prediction

Explaining Temporal Graph Models Through An Explorer-Navigator Framework

Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic

Fooling SHAP with Stealthily Biased Sampling

Concept-level Debugging of Part-Prototype Networks

ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations

Global Explainability of GNNs Via Logic Combination of Learned Concepts

Re-calibrating Feature Attributions for Model Interpretation

How to Train Your HIPPO: State Space Models with Generalized Orthogonal Basis Projections

A Differential Geometric View and Explainability of GNN on Evolving Graphs

On Explaining Neural Network Robustness with Activation Path

Robust Explanation Constraints for Neural Networks

Understanding The Generalization of Adam in Learning Neural Networks with Proper Regularization

DrML: Diagnosing and Rectifying Vision Models Using Language

DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks

GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks

Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and Its Superiority to Kernel Methods

Heavy-tailed Noise Does Not Explain The Gap Between SGD and Adam, But Sign Descent Might

Emergence of Maps in The Memories of Blind Navigation Agents
