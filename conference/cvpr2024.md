## adversarial

Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models

Random Entangled Tokens for Adversarially Robust Vision Transformer

Robust Distillation via Untargeted and Targeted Intermediate Adversarial Samples

dversarially Robust Few-shot Learning via Parameter Co-distillation of Similarity and Class Concept Learners

Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving

Hide in Thicket: Generating Imperceptible and Rational Adversarial Perturbations on 3D Point Clouds

PeerAiD: Improving Adversarial Distillation from a Specialized Peer Tutor

Adversarial Distillation Based on Slack Matching and Attribution Region Alignment

Soften to Defend: Towards Adversarial Robustness via Self-Guided Label Refinement

Structured Gradient-based Interpretations via Norm-Regularized Adversarial Training

Dispel Darkness for Better Fusion: A Controllable Visual Enhancer based on Cross-modal Conditional Adversarial Learning

ACT-Diffusion: Efficient Adversarial Consistency Training for One-step Diffusion Models

MMCert: Provable Defense against Adversarial Attacks to Multi-modal Models

Infrared Adversarial Car Stickers

Boosting Adversarial Transferability by Block Shuffle and Rotation


One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models

Adversarial Text to Continuous Image Generation

Robust Overfitting Does Matter: Test-Time Adversarial Purification With FGSM

MimicDiffusion: Purifying Adversarial Perturbation via Mimicking Clean Diffusion Model

Defense Against Adversarial Attacks on No-Reference Image Quality Models with Gradient Norm Regularization

Semantic-Aware Multi-Label Adversarial Attacks


Transferable Structural Sparse Adversarial Attack Via Exact Group Sparsity Training

On The Vulnerability of Efficient Vision Transformers to Adversarial Computation Attacks

Learning to Transform Dynamically for Better Adversarial Transferability

DAP: A Dynamic Adversarial Patch for Evading Person Detectors

Language-Driven Anchors for Zero-Shot Adversarial Robustness

Robust Image Denoising through Adversarial Frequency Mixup

Initialization Matters for Adversarial Transfer Learning

NAPGuard: Towards Detecting Naturalistic Adversarial Patches

ASAM: Boosting Segment Anything Model with Adversarial Tuning

Towards Fairness-Aware Adversarial Learning


Towards Transferable Targeted 3D Adversarial Attack in the Physical World


Attack To Defend: Exploiting Adversarial Attacks for Detecting Poisoned Models


Towards Understanding and Improving Adversarial Robustness of Vision Transformers

Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving

PAD: Patch-Agnostic Defense against Adversarial Patch Attacks

Revisiting Adversarial Training at Scale

Adversarial Score Distillation: When score distillation meets GAN

Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial Training

Towards Robust 3D Pose Transfer with Adversarial Learning

Strong Transferable Adversarial Attacks via Ensembled Asymptotically Normal Distribution Learning

Ensemble Diversity Facilitates Adversarial Transferability

Structure-Guided Adversarial Training of Diffusion Models

Revisiting Adversarial Training under Long-Tailed Distributions

Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial Robustness


Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay

DiffAM: Diffusion-based Adversarial Makeup Transfer for Facial Privacy Protection

On the Robustness of Large Multimodal Models Against Image Adversarial Attacks

Improving Transferable Targeted Adversarial Attacks with Model Self-Enhancement

CAD: Photorealistic 3D Generation via Adversarial Distillation

## Saliency

Realigning Confidence with Temporal Saliency Information for Point-level Weakly-Supervised Temporal Action Localization

Advancing Saliency Ranking with Human Fixations: Dataset, Models and Benchmarks


Domain Separation Graph Neural Networks for Saliency Object Ranking

DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction

CosalPure: Learning Concept from Group Images for Robust Co-Saliency Detection


Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental Learning

## interpretability

Selective, Interpretable and Motion Consistent Privacy Attribute Obfuscation for Action Recognition

Visual Objectification in Films: Towards a New AI Task for Video Interpretation

Self-Discovering Interpretable Diffusion Latent Directions for Responsible Text-to-Image Generation

WWW: A Unified Framework for Explaining What, Where and Why of Neural Networks by Interpretation of Neuron Concept

MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes

NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models

SkySense: A Multi-Modal Remote Sensing Foundation Model Towards Universal Interpretation for Earth Observation Imagery

A Unified and Interpretable Emotion Representation and Expression Generation

CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation

Language Model Guided Interpretable Video Action Reasoning

Building Optimal Neural Architectures using Interpretable Knowledge

Interpretable Measures of Conceptual Similarity by Complexity-Constrained Descriptive Auto-Encoding

SkillDiffuser: Interpretable Hierarchical Planning via Skill Abstractions in Diffusion-Based Task Execution

SI-MIL: Taming Deep MIL for Self-Interpretability in Gigapixel Histopathology

## Explanation

Improved Visual Grounding through Self-Consistent Explanations

Can Biases in ImageNet Models Explain Generalization?

SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection


SLICE: Stabilized LIME for Consistent Explanations for Image Classification

What Sketch Explainability Really Means for Downstream Tasks ?

Explaining CLIP's performance disparities on data from blind/low vision users

Comparing the Decision-Making Mechanisms by Transformers and CNNs via Explanation Methods

E-GPS: Explainable Geometry Problem Solving via Top-Down Solver and Bottom-Up Generator

WWW: A Unified Framework for Explaining What, Where and Why of Neural Networks by Interpretation of Neuron Concept


Discovering and Mitigating Visual Biases through Keyword Explanation

Token Transformation Matters: Towards Faithful Post-hoc Explanation for Vision Transformer

On the Faithfulness of Vision Transformer Explanations

DiG-IN: Diffusion Guidance for Investigating Networks - Uncovering Classifier Differences, Neuron Visualisations, and Visual Counterfactual Explanations

Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions

ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations
